{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STAT547O - Bootstrap notes\n",
    "================\n",
    "Matias Salibian-Barrera\n",
    "2019-11-22\n",
    "\n",
    "#### LICENSE\n",
    "\n",
    "These notes are released under the “Creative Commons\n",
    "Attribution-ShareAlike 4.0 International” license. See the\n",
    "**human-readable version**\n",
    "[here](https://creativecommons.org/licenses/by-sa/4.0/) and the **real\n",
    "thing**\n",
    "[here](https://creativecommons.org/licenses/by-sa/4.0/legalcode).\n",
    "\n",
    "# DRAFT (Read at your own risk)\n",
    "\n",
    "## The Fast and Robust Bootstrap\n",
    "\n",
    "Before we describe the fast and robust bootstrap (FRB) we briefly\n",
    "illustrate the use of the non-parametric bootstrap (Efron 1979) with a\n",
    "less-trivial example than the ones often used in tutorials.\n",
    "\n",
    "### Efron’s non-parametric Bootstrap\n",
    "\n",
    "Consider the problem of constructing a confidence region (or confidence\n",
    "intervals) for the eigenvalues of the covariance matrix of a random\n",
    "vector. To simplify the presentation we consider here a bi-variate case\n",
    "`p = 2`). In order to construct these confidence sets we need to\n",
    "estimate the (joint) distribution of the eigenvalue estimators. We will\n",
    "use non-parametric boostrap to do this.\n",
    "\n",
    "We first generate a random sample of `n = 200` observations from a\n",
    "2-dimensional Gaussian random vector with mean 0. The true covariance\n",
    "matrix has eigenvalues 12 and 3, and we randomly pick the corresponding\n",
    "eigenvectors (from a uniform distribution on the unit ball). If `U` is\n",
    "the matrix containing the eigenvectors as columns (so that `U'U = I`),\n",
    "then the covariance matrix of the bi-variate random vector is `\\Sigma =\n",
    "U \\Lambda U^T`, where `\\Lambda = diag(12, 3)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p <- 2\n",
    "set.seed(123456)\n",
    "u <- qr.Q( qr( matrix(rnorm(p*p), p, p) ) )\n",
    "la <- c(12, 3) \n",
    "sigma <- u %*% diag(la) %*% t(u) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now take the random sample of `n = 200` observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n <- 200\n",
    "set.seed(123456)\n",
    "x <- MASS::mvrnorm(n=n, mu=rep(0,p), Sigma=sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated eigenvalues of the true covariance matrix `\\Sigma` are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "( la.hat <- svd(cov(x))$d )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(recall that the true ones are 12, 3). To construct 95% confidence\n",
    "intervals for the each of the true eigenvalues, or build a 95%\n",
    "confidence region for both of them simultaneously we need to estimate\n",
    "the distribution of the random vector `(\\hat{\\lambda}_1,\n",
    "\\hat{\\lambda}_2)^T`. The non-parametric bootstrap (Efron 1979) estimator\n",
    "for this distribution. is the “empirical” (Monte Carlo) distribution\n",
    "obtained by re-computing the estimator on `B` samples obtained from the\n",
    "original sample, with replacement. In this example we will use `B = 500`\n",
    "bootstrap samples.\n",
    "\n",
    "For each sample we will compute the eigenvalues of the corresponding\n",
    "sample covariance matrix. The empirical distribution of these 500\n",
    "bi-variate vectors constitutes the nonparametric bootstrap estimate of\n",
    "the distribution of interest. We will save these 500 vectors in the\n",
    "matrix `la.hat.b` below. The main bootstrap loop is below. In each step\n",
    "we draw a sample from the original sample and compute the eigenvalues of\n",
    "the sample covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B <- 500\n",
    "la.hat.b <- array(0, dim=c(B, p))\n",
    "set.seed(123456)\n",
    "for(j in 1:B) {\n",
    "  ii <- sample(n, repl=TRUE)\n",
    "  la.hat.b[j, ] <- svd( cov(x[ii,]) )$d\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot below displays the estimated distribution of the vector of\n",
    "eigenvalues etimators. The red point is the center of the estimated\n",
    "distribution, and the blue point is the original vector of estimated\n",
    "eigenvalues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(la.hat.b, pch=19, col='gray')\n",
    "la.mu <- colMeans(la.hat.b)\n",
    "points(la.mu[1], la.mu[2], col='red', pch=19, cex=1.2)\n",
    "points(la.hat[1], la.hat[2], col='blue', pch=19, cex=1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This distribution looks fairly elliptical (and Gaussian). We can draw a\n",
    "95% confidence region based on this observation (the green ellipse\n",
    "below). Note that the the true vector of eigenvalues (indicated with a\n",
    "light blue point on the plot) falls inside the confidence region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa <- var(la.hat.b) \n",
    "plot(la.hat.b, pch=19, col='gray')\n",
    "xx <- ellipse::ellipse(aa, centre=la.mu)\n",
    "lines(xx, cex=.7, col='darkgreen', lwd=3)\n",
    "points(la.mu[1], la.mu[2], col='red', pch=19, cex=1.2)\n",
    "points(la[1], la[2], col='steelblue', pch=19, cex=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build marginal confidence intervals, we use quantiles of the\n",
    "estimated marginal distributions. For the first eigenvalue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs <- as.numeric( quantile(la.hat.b[,1] - la.mu[1], c(.025, .975)) )\n",
    "c(la.mu[1] - qs[2], la.mu[1] - qs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and for the second eigenvalue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs <- as.numeric( quantile(la.hat.b[,2] - la.mu[2], c(.025, .975)) )\n",
    "c(la.mu[2] - qs[2], la.mu[2] - qs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fast and Robust Bootstrap (for an M-estimator of location)\n",
    "\n",
    "In this note we discuss the Fast and Robust Bootstrap (FRB) in the\n",
    "simple case of M-estimators for a location parameter. The FRB has been\n",
    "applied to many several models and estimators. A review paper is SB, Van\n",
    "Aelst, & Willems (2008) Fast and robust bootstrap, *Statistical Methods\n",
    "and Applications*, 17(1): 41-71.\n",
    "[DOI](https://doi.org/10.1007/s10260-007-0048-6); and the original paper\n",
    "is SB & Zamar (2002) Bootrapping robust estimates of regression, *The\n",
    "Annals of Statistics*, 30(2), 556-582\n",
    "[DOI](https://doi.org/10.1214/aos/1021379865).\n",
    "\n",
    "When bootstrapping robust estimators with data that may contain ayptical\n",
    "observations two main issues arise: (a) re-computing the robust\n",
    "estimator several hundred times may be computationally too constly (or\n",
    "unfeasible); and (b) some of the bootstrap samples may contain a larger\n",
    "proportion of outliers than in the original sample, and thus the\n",
    "bootstrapped estimators may be heavily influenced by them.\n",
    "\n",
    "The Fast and Robust Bootstrap avoids both problems above: it is very\n",
    "fast (for each bootstrap sample we only need to compute a weighted\n",
    "average or weighted least squares estimator), and since each point in\n",
    "the sample is associated with their estimating equations weights (which\n",
    "are typically low for observations that were not well fit), outliers\n",
    "will be downweighted and thus will not affect the bootstrapped\n",
    "estimators.\n",
    "\n",
    "We described this method in class. Here is an application to the\n",
    "simplest M-estimator of location (where the residual scale is assumed\n",
    "known).\n",
    "\n",
    "We first create a toy example with a synthetic simple data set\n",
    "consisting of `n = 50` observations, including 10% of outliers following\n",
    "a `N(5, 0.01)` distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(123456)\n",
    "n <- 50\n",
    "ep <- .1\n",
    "n0 <- floor(n*(1-ep))\n",
    "x <- c(rnorm(n0), rnorm(n-n0, mean=5, sd=.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The true location parameter is 0, the sample mean is 0.648 and the\n",
    "sample median is 0.18.\n",
    "\n",
    "We now compute a robust M-estimator using a bisquare score function\n",
    "(tuned to achieve 90% efficiency if no outliers were present in the\n",
    "data), and the usual iterative re-weighted least-squares algorithm. Note\n",
    "that in this example we estimate the residual scale with the MAD and\n",
    "keep it fixed (essentially assuming that the scale is known). The proper\n",
    "way to do this is, of course, to include the scale estimation step in\n",
    "the process (see the references at the top of this section).\n",
    "\n",
    "We first write a simple function to compute the M-estimator with the\n",
    "iterative re-weighted least-squares algorithm (which are re-weigthed\n",
    "averages in this simple setting):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mlocation <- function(x, cc0, si.hat, max.it=100, tol=1e-7) { \n",
    "  mu.hat <- median(x)\n",
    "  rhoprime <- function(r, family='bisquare', cc=cc0) {\n",
    "    return(RobStatTM::rhoprime(r, family=family, cc=cc) )\n",
    "  }\n",
    "  mu.old <- mu.hat + 10*tol\n",
    "  j <- 0\n",
    "  while( (j  < max.it) & (abs(mu.old - mu.hat) > tol) ) {\n",
    "    mu.old <- mu.hat\n",
    "    re <- (x - mu.hat) / si.hat\n",
    "    w <- rhoprime(re) / re\n",
    "    w[ abs(re) < .Machine$double.eps ] <- 1\n",
    "    mu.hat <- sum(w * x ) / sum(w)\n",
    "    j <- j + 1\n",
    "  }\n",
    "  return(mu.hat)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use this function to compute the M-estimator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc0 <- RobStatTM::lmrobdet.control(family='bisquare', \n",
    "                                   efficiency=.9)$tuning.psi\n",
    "si.hat <- mad(x) \n",
    "( round(mu.hat <- Mlocation(x, cc0=cc0, si.hat=si.hat), 3) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed in class, bootstrapping using the above fixed\n",
    "estimating-equation-weights (`w`) can be expected to underestimate the\n",
    "variability of the target distribution, but this can be corrected by\n",
    "applying a simple correction factor (which can be derived using a Taylor\n",
    "expansion of the fixed-point estimating equations). We now compute this\n",
    "correction factor, which in this setting is a scalar (`corr.f` below):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re <- (x - mu.hat)/si.hat\n",
    "w <- RobStatTM::rhoprime(re, family='bisquare', cc=cc0) / re\n",
    "tmp1 <- RobStatTM::rhoprime(re, family='bisquare', cc=cc0)\n",
    "tmp2 <- RobStatTM::rhoprime2(re, family='bisquare', cc=cc0)\n",
    "wprime <- (tmp1 - tmp2*re)/re^2\n",
    "swp <- sum(wprime)\n",
    "wwprime <- ( wprime * sum(w) - wprime * swp ) / ( sum(w) )^2\n",
    "corr.f <- 1 / ( 1 - sum( wwprime * x ) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now compute the 500 bootstrapped M-estimators. Note that, instead of\n",
    "running the above re-weighted least squares iterations (re-weighted\n",
    "means in this simple setting) until convergence to compute the\n",
    "M-estimator with each bootstrap sample, we only need to compute a\n",
    "weighted average of the form `sum(w*x)/sum(w)`, which is very fast,\n",
    "using the bootstrap sample of `x`’s and their corresponding weights\n",
    "`w`’s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B <- 500\n",
    "mu.hat.b <- vector('numeric', B)\n",
    "set.seed(123456)\n",
    "system.time({ \n",
    "  for(j in 1:B) {\n",
    "    ii <- sample(n, repl=TRUE)\n",
    "    mu.hat.b[j] <- sum( w[ii] * x[ii] ) / sum( w[ii] )\n",
    "  }\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the running time, which we will compare below with the time it\n",
    "takes to run the standard bootstrap.\n",
    "\n",
    "Next we use the quantiles of the centered and corrected bootstrap\n",
    "distribution to construct the 95% confidence interval for the true\n",
    "location parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boot.cc <- corr.f*(mu.hat.b - mu.hat)\n",
    "uu <- quantile( boot.cc, c(.025, .975))\n",
    "c( mu.hat - uu[2], mu.hat - uu[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bootstraping the M-estimator “by hand”\n",
    "\n",
    "We now use the non-parametric bootstrap to estimate the distribution of\n",
    "the M-estimator of location (keeping the scale fixed). We show the\n",
    "required running time, to compare it with that of the FRB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "si.hat <- mad(x)\n",
    "B <- 500\n",
    "mu.hat.b2 <- vector('numeric', B)\n",
    "set.seed(123456)\n",
    "system.time({\n",
    "  for(j in 1:B) {\n",
    "    ii <- sample(n, repl=TRUE)\n",
    "    mu.hat.b2[j] <- Mlocation(x[ii], cc0=cc0, si.hat=si.hat)\n",
    "  }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, even in this very simple example, the FRB is approximately 10\n",
    "times faster than the usual bootstrap for these estimators. The\n",
    "resulting confidence interval is very similar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uu <- quantile( mu.hat.b2 - mu.hat, c(.025, .975))\n",
    "c( mu.hat - uu[2], mu.hat - uu[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence intervals based on the mean and the median\n",
    "\n",
    "Finally, we compare the confidence interval based on the M-estimator\n",
    "with those based on the sample mean and the sample median. It is not\n",
    "surprising that the classical 95% confidence interval based on the\n",
    "sample mean fails to contain the true value (zero):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c(mean(x) - qnorm(.975) * sd(x)/sqrt(n), \n",
    "mean(x) + qnorm(.975) * sd(x)/sqrt(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To construct a confidence interval based on the sample median we require\n",
    "an estimate of the density of the error distribution. Using a kernel\n",
    "estimator we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a <- summary(quantreg::rq(x ~ 1), se='ker')$coef\n",
    "c( a[1] - qnorm(.975) * a[2], a[1] + qnorm(.975) * a[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using bootstrap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a <- summary(quantreg::rq(x ~ 1), se='boot')$coef\n",
    "c( a[1] - qnorm(.975) * a[2], a[1] + qnorm(.975) * a[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is interesting to note that the two confidence intervals above are\n",
    "noticeably wider than those computed with the M-estimator, reflecting\n",
    "the gain in efficiency obtained by using an M-estimator instead of the\n",
    "median."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
